{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d3001-a82e-434a-aa53-9bd08518bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re\n",
    "import requests, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1a979-fa6a-4b65-962a-69a92c673061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiramente vamos criar uma lista com todos os filmes lançados entre 01/01/2000 e 31/12/2021 (total de 247,584 filmes)\n",
    "url_base = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie&release_date=2020-01-01,2021-12-31'\n",
    "response = requests.get(url_base)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41b3ab-be7b-4ca5-b627-72a8f94ec99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando o HTML para poder abrir em um editor e ficar mais fácil de trabalhar\n",
    "soup = BeautifulSoup(response.content, features = 'lxml')\n",
    "with open(\"url_base.html\", \"w\", encoding='utf-8') as file:\n",
    "    file.write(str(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a11cd-c4b9-4212-a20d-5653c4de4472",
   "metadata": {},
   "source": [
    "Coletar as informações da página antes de criar um loop\n",
    "Dessa página precisamos tirar:\n",
    "1. Movie Link\n",
    "2. Next page link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd630d3-91a9-454c-989f-9769bed78b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_detail = soup.find_all('div', attrs = {'class':'lister-item-content'})\n",
    "link = list_detail[0]\n",
    "linkID = link.a['href']\n",
    "linkMovie = f'https://www.imdb.com{linkID}'\n",
    "linkMovie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48f15e-1b47-4d7b-ab94-8dc5a2735877",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkNext1 = soup.find_all('a', attrs = {'class':'lister-page-next next-page'})[0]\n",
    "linknext = linkNext1['href']\n",
    "linkNext = f'https://www.imdb.com{linknext}'\n",
    "linkNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd107f-d2e4-4aab-b1f8-53cef517b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista que contenha todos os links de filmes na página     \n",
    "list_detail = soup.find_all('div', attrs = {'class':'lister-item-content'})\n",
    "url_list = [\"https://www.imdb.com\" + link.a['href'] for link in list_detail]\n",
    "print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997c588-e34d-451a-b199-8a7fef5e2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie&release_date=2020-01-01,2021-12-31'\n",
    "url_list = []\n",
    "\n",
    "try:\n",
    "    for i in range (0,541):\n",
    "        if i <= 539:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, features = 'lxml')\n",
    "\n",
    "            list_detail = soup.find_all('div', attrs = {'class':'lister-item-content'})\n",
    "            url_list_now = [\"https://www.imdb.com\" + link.a['href'] for link in list_detail]\n",
    "            url_list.append(url_list_now)\n",
    "            \n",
    "            try:\n",
    "                linkNext1 = soup.find_all('a', attrs = {'class':'lister-page-next next-page'})[0]\n",
    "                linknext = linkNext1['href']\n",
    "                url = f'https://www.imdb.com{linknext}'\n",
    "            except:\n",
    "                url = url\n",
    "\n",
    "        else:   \n",
    "            flat_list = [item for lista in url_list for item in lista]\n",
    "except:\n",
    "    print(f'issue with this link: {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea4ccc-bfd5-4ef8-b141-038c3cd589bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se há links duplicados\n",
    "print(len(flat_list))\n",
    "set_links = list(set(flat_list))\n",
    "print(len(set_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fd762-da1c-4f6d-9554-d5e54c59a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar em um arquivo, pois o código era muito pesado e não quero ter que rodar toda vez\n",
    "movies_list = pd.DataFrame (set_links, columns = ['imdb_link'])\n",
    "movies_list.to_csv('lista_imdb_links_2020_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6014ca-3476-45ee-9c89-be5997420994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar dados da página do filme\n",
    "link = 'https://www.imdb.com/title/tt9032400/?ref_=adv_li_tt'\n",
    "response = requests.get(link)\n",
    "soup = BeautifulSoup(response.content, features = 'lxml')\n",
    "\n",
    "# 1. Movie ID\n",
    "imdbID = link.replace('https://www.imdb.com/title/','').replace('/?ref_=adv_li_tt','')\n",
    "print(imdbID)\n",
    "# 2. link para a página de avaliações\n",
    "rating_link = f'{link}ratings/?ref_=tt_ov_rt'\n",
    "print(rating_link)\n",
    "# 3. nome do filme\n",
    "movie_name = soup.title.text\n",
    "movie_name = movie_name.replace(' - IMDb','')\n",
    "print(movie_name)\n",
    "# 4. ano de lançamento do filme\n",
    "try:\n",
    "    year = soup.find_all('ul', attrs = {'data-testid':\"hero-title-block__metadata\"})[0].text\n",
    "    year = re.findall(r'[0-9]{4}', year)\n",
    "    year = year[0]\n",
    "except:\n",
    "    year = ''\n",
    "print(year)\n",
    "# 5. nota do IMDB\n",
    "try:\n",
    "    imdb_rating = soup.find_all('span', attrs = {'class':\"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})[0].text\n",
    "except:\n",
    "    imdb_rating = ''\n",
    "print(imdb_rating)\n",
    "# 6. quantidade de votos\n",
    "try:\n",
    "    user_votes = soup.find_all('div', attrs = {'class':\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\"})[0].text\n",
    "except:\n",
    "    user_votes = ''\n",
    "print(user_votes)\n",
    "# 7. nome do diretor\n",
    "try:\n",
    "    director = soup.find_all('a', attrs = {'class':\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\"})[0].text\n",
    "except:\n",
    "    director = ''\n",
    "print(director)\n",
    "# 8. prêmios ganhos e nomeações (testei em caso o filme não tenha premiações)\n",
    "try:\n",
    "    awards = soup.find_all('li', attrs = {'data-testid':\"award_information\"})[0].text\n",
    "except:\n",
    "    awards = ''\n",
    "print(awards)    \n",
    "# 9. oscars\n",
    "oscars = re.findall(r'(\\d+)(?=\\s*Oscar)', awards)[0]\n",
    "print(oscars)\n",
    "# 10. prêmios ganhos\n",
    "awards_won = re.findall(r'(\\d+)(?=\\s*win)', awards)[0]\n",
    "print(awards_won)\n",
    "# 11. nomeações\n",
    "awards_nominated = re.findall(r'(\\d+)(?=\\s*nomination)', awards)[0]\n",
    "print(awards_nominated)\n",
    "# 12. gêneros\n",
    "try:\n",
    "    genres_html = soup.find_all('div', attrs = {'data-testid':\"genres\"})[0]\n",
    "    genre = genres_html.find_all('a', attrs = {'class':'GenresAndPlot__GenreChip-sc-cum89p-3 LKJMs ipc-chip ipc-chip--on-baseAlt'})\n",
    "    genres = [x.text for x in genre]\n",
    "except:\n",
    "    genres = ''\n",
    "print(genres)\n",
    "# 13. país\n",
    "try:\n",
    "    country_htlm = soup.find_all('li', attrs = {'data-testid':\"title-details-origin\"})[0]\n",
    "    countries = country_htlm.find_all('a', attrs = {'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
    "    country = [x.text for x in countries]\n",
    "except:\n",
    "    country = ''\n",
    "print(country)\n",
    "# 14. língua\n",
    "try:\n",
    "    languages_htlm = soup.find_all('li', attrs = {'data-testid':\"title-details-languages\"})[0]\n",
    "    language = languages_htlm.find_all('a', attrs = {'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
    "    languages = [x.text for x in language]\n",
    "except:\n",
    "    languages = ''\n",
    "print(languages)\n",
    "# 15. orçamento\n",
    "try:\n",
    "    boxoffice_budget = soup.find_all('li', attrs = {'data-testid':\"title-boxoffice-budget\"})[0].text\n",
    "    boxoffice_budget = boxoffice_budget.replace('Budget','').replace(' (estimated)','')\n",
    "    boxoffice_budget = re.findall(r'[0-9]*', boxoffice_budget)\n",
    "    boxoffice_budget = ''.join(str(x) for x in boxoffice_budget)\n",
    "except:\n",
    "    boxoffice_budget = ''\n",
    "print(boxoffice_budget)\n",
    "# 16. receita\n",
    "try:\n",
    "    gross_worldwide = soup.find_all('li', attrs = {'data-testid':\"title-boxoffice-cumulativeworldwidegross\"})[0].text\n",
    "    gross_worldwide = gross_worldwide.replace('Gross worldwide','').replace(' (estimated)','')\n",
    "    gross_worldwide = re.findall(r'[0-9]*', gross_worldwide)\n",
    "    gross_worldwide = ''.join(str(x) for x in gross_worldwide)\n",
    "except:\n",
    "    gross_worldwide = ''\n",
    "print(gross_worldwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78a7b8-9bd9-40d0-afad-000accc471b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list_df = pd.read_csv ('lista_imdb_links_2020_2021.csv')\n",
    "flat_list_df.head(2)\n",
    "flat_list = flat_list_df['imdb_link'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266c721-8e1b-42b1-b6cb-98ccc6451657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for link in flat_list:\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, features = 'lxml')\n",
    "        \n",
    "        # get the data from the movie IMDB page\n",
    "        imdbID = link.replace('https://www.imdb.com/title/','').replace('/','')\n",
    "        # 2. link para a página de avaliações\n",
    "        rating_link = f'{link}ratings/?ref_=tt_ov_rt'\n",
    "        # 3. nome do filme\n",
    "        movie_name = soup.title.text\n",
    "        movie_name = movie_name.replace(' - IMDb','')\n",
    "        # 4. ano de lançamento do filme\n",
    "        try:\n",
    "            year = soup.find_all('ul', attrs = {'data-testid':\"hero-title-block__metadata\"})[0].text\n",
    "            year = re.findall(r'[0-9]{4}', year)\n",
    "            year = year[0]\n",
    "        except:\n",
    "            year = ''\n",
    "        # 5. nota do IMDB\n",
    "        try:\n",
    "            imdb_rating = soup.find_all('span', attrs = {'class':\"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})[0].text\n",
    "        except:\n",
    "            imdb_rating = ''\n",
    "        # 6. quantidade de votos\n",
    "        try:\n",
    "            user_votes = soup.find_all('div', attrs = {'class':\"AggregateRatingButton__TotalRatingAmount-sc-1ll29m0-3 jkCVKJ\"})[0].text\n",
    "        except:\n",
    "            user_votes = ''\n",
    "        # 7. nome do diretor\n",
    "        try:\n",
    "            director = soup.find_all('a', attrs = {'class':\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\"})[0].text\n",
    "        except:\n",
    "            director = ''\n",
    "        # 8. prêmios ganhos e nomeações (testei em caso o filme não tenha premiações)\n",
    "        try:\n",
    "            awards = soup.find_all('li', attrs = {'data-testid':\"award_information\"})[0].text\n",
    "        except:\n",
    "            awards = ''\n",
    "        # 9. oscars\n",
    "        try:\n",
    "            oscars = re.findall(r'(\\d+)(?=\\s*Oscar)', awards)[0]\n",
    "        except:\n",
    "            oscars = 0\n",
    "        # 10. prêmios ganhos\n",
    "        try:\n",
    "            awards_won = re.findall(r'(\\d+)(?=\\s*win)', awards)[0]\n",
    "        except:\n",
    "            awards_won = 0\n",
    "        # 11. nomeações\n",
    "        try:\n",
    "            awards_nominated = re.findall(r'(\\d+)(?=\\s*nomination)', awards)[0]\n",
    "        except:\n",
    "            awards_nominated = 0\n",
    "        # 12. gêneros\n",
    "        try:\n",
    "            genres_html = soup.find_all('div', attrs = {'data-testid':\"genres\"})[0]\n",
    "            genre = genres_html.find_all('a', attrs = {'class':'GenresAndPlot__GenreChip-sc-cum89p-3 LKJMs ipc-chip ipc-chip--on-baseAlt'})\n",
    "            genres = [x.text for x in genre]\n",
    "        except:\n",
    "            genres = ''\n",
    "        # 13. país\n",
    "        try:\n",
    "            country_htlm = soup.find_all('li', attrs = {'data-testid':\"title-details-origin\"})[0]\n",
    "            countries = country_htlm.find_all('a', attrs = {'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
    "            country = [x.text for x in countries]\n",
    "        except:\n",
    "            country = ''\n",
    "        # 14. língua\n",
    "        try:\n",
    "            languages_htlm = soup.find_all('li', attrs = {'data-testid':\"title-details-languages\"})[0]\n",
    "            language = languages_htlm.find_all('a', attrs = {'class':'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
    "            languages = [x.text for x in language]\n",
    "        except:\n",
    "            languages = ''\n",
    "        # 15. orçamento\n",
    "        try:\n",
    "            boxoffice_budget = soup.find_all('li', attrs = {'data-testid':\"title-boxoffice-budget\"})[0].text\n",
    "            boxoffice_budget = boxoffice_budget.replace('Budget','').replace(' (estimated)','')\n",
    "            boxoffice_budget = re.findall(r'[0-9]*', boxoffice_budget)\n",
    "            boxoffice_budget = ''.join(str(x) for x in boxoffice_budget)\n",
    "        except:\n",
    "            boxoffice_budget = ''\n",
    "        # 16. receita\n",
    "        try:\n",
    "            gross_worldwide = soup.find_all('li', attrs = {'data-testid':\"title-boxoffice-cumulativeworldwidegross\"})[0].text\n",
    "            gross_worldwide = gross_worldwide.replace('Gross worldwide','').replace(' (estimated)','')\n",
    "            gross_worldwide = re.findall(r'[0-9]*', gross_worldwide)\n",
    "            gross_worldwide = ''.join(str(x) for x in gross_worldwide)\n",
    "        except:\n",
    "            gross_worldwide = ''\n",
    "        \n",
    "        # Create a dictionary\n",
    "        data.append({'imdbID': imdbID,\n",
    "                     'movie_name':movie_name,\n",
    "                     'year':year,\n",
    "                     'imdb_rating':imdb_rating,\n",
    "                     'rating_link':rating_link,\n",
    "                     'user_votes':user_votes,\n",
    "                     'director':director,\n",
    "                     'oscars':oscars,\n",
    "                     'awards_won':awards_won,\n",
    "                     'awards_nominated':awards_nominated,\n",
    "                     'genres':genres,\n",
    "                     'country':country,\n",
    "                     'languages':languages,\n",
    "                     'boxoffice_budget':boxoffice_budget,\n",
    "                     'gross_worldwide':gross_worldwide})\n",
    "        \n",
    "    except:\n",
    "        print(f'issue with this link: {link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6047be-b7d5-40c1-a05d-3e75d2a8892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar em um arquivo, pois o código era muito pesado e não quero ter que rodar toda vez\n",
    "movies_data = pd.DataFrame(data)\n",
    "movies_data.to_csv('movies_data_imdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38e164-860a-4720-8248-dd57bc399444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating soup\n",
    "link_erro = []\n",
    "\n",
    "for link in flat_list:\n",
    "    \n",
    "    try:\n",
    "        rating_link = f'{link}ratings/'\n",
    "        response = requests.get(rating_link)\n",
    "        soup = BeautifulSoup(response.content, features = 'lxml')\n",
    "        \n",
    "        # Extracting Movie name\n",
    "        imdbID = link.replace('https://www.imdb.com/title/','').replace('/','')\n",
    "        \n",
    "        # Extracting table\n",
    "        tables = soup.find_all('table')[1]\n",
    "        \n",
    "        # Extracting columns' names\n",
    "        colname = tables.find_all('div', attrs = {'class':'tableHeadings'})\n",
    "        colnames = [col.text.split(\"\\n\") for col in colname]\n",
    "        flat_colnames = [item for sublist in colnames for item in sublist]\n",
    "        \n",
    "        # Extracting all rows\n",
    "        row = tables.find_all('div', attrs = {'class':'bigcell'})\n",
    "        rows = [r.text.split(\"\\n\") for r in row]\n",
    "        flat_rows = [item for sublist in rows for item in sublist]\n",
    "        \n",
    "        splited = []\n",
    "        len_l = len(flat_rows)\n",
    "        for i in range(3):\n",
    "            start = int(i*len_l/3)\n",
    "            end = int((i+1)*len_l/3)\n",
    "            splited.append(flat_rows[start:end])\n",
    "        \n",
    "        # Extracting columns gender\n",
    "        col_gender = tables.find_all('div', attrs = {'class':'leftAligned'})\n",
    "        col_gender = [i.text for i in col_gender]\n",
    "        \n",
    "        df = pd.DataFrame(splited, columns = flat_colnames)\n",
    "        df.insert(0, 'Movie Id', imdbID)\n",
    "        df.insert(1, 'Gender', col_gender)\n",
    "        \n",
    "        try:\n",
    "            imdb_ratings = pd.concat([imdb_ratings,df])\n",
    "        except:\n",
    "            imdb_ratings = df\n",
    "            \n",
    "    except:\n",
    "        link_erro.append(rating_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef6a18-4ebe-4a8e-8b32-5510c7b42200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar em um arquivo, pois o código era muito pesado e não quero ter que rodar toda vez\n",
    "imdb_ratings.to_csv('movies_ratings_imdb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
