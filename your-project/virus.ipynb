{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['multiTimeline.csv',\n",
       " 'virusds.ipynb',\n",
       " 'tweetscount.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'virus.ipynb',\n",
       " 'README.md',\n",
       " 'virusds.csv',\n",
       " 'geoMap.csv',\n",
       " 'google_trend_country.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json \n",
    "from pandas.io.json import json_normalize\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from getpass import getpass\n",
    "import this\n",
    "\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get pandas to show 999 rows of the dataframes\n",
    "#pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ds into dataframe\n",
    "virus = pd.read_csv(\"virusds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Guangxi</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Guizhou</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Hainan</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>01/22/2020 12:00:00</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno                 Date Province/State Country          Last Update  \\\n",
       "0    1  01/22/2020 12:00:00          Anhui   China  2020-01-22 12:00:00   \n",
       "1    2  01/22/2020 12:00:00        Beijing   China  2020-01-22 12:00:00   \n",
       "2    3  01/22/2020 12:00:00      Chongqing   China  2020-01-22 12:00:00   \n",
       "3    4  01/22/2020 12:00:00         Fujian   China  2020-01-22 12:00:00   \n",
       "4    5  01/22/2020 12:00:00          Gansu   China  2020-01-22 12:00:00   \n",
       "5    6  01/22/2020 12:00:00      Guangdong   China  2020-01-22 12:00:00   \n",
       "6    7  01/22/2020 12:00:00        Guangxi   China  2020-01-22 12:00:00   \n",
       "7    8  01/22/2020 12:00:00        Guizhou   China  2020-01-22 12:00:00   \n",
       "8    9  01/22/2020 12:00:00         Hainan   China  2020-01-22 12:00:00   \n",
       "9   10  01/22/2020 12:00:00          Hebei   China  2020-01-22 12:00:00   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  \n",
       "0        1.0     0.0        0.0  \n",
       "1       14.0     0.0        0.0  \n",
       "2        6.0     0.0        0.0  \n",
       "3        1.0     0.0        0.0  \n",
       "4        0.0     0.0        0.0  \n",
       "5       26.0     0.0        0.0  \n",
       "6        2.0     0.0        0.0  \n",
       "7        1.0     0.0        0.0  \n",
       "8        4.0     0.0        0.0  \n",
       "9        1.0     0.0        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# documentation \n",
    "\"\"\"\n",
    "Sno —> Serial number —> int\n",
    "Date —> Date and time of observation —> date\n",
    "Province/State —> Province or State of observation —> str\n",
    "Country —> Country of observation —> str\n",
    "Last Update —> Last update date of the row in UTC -> date\n",
    "Confirmed —> Number of confirmed cases —> decimal\n",
    "Deaths —> Number of deaths —> decimal\n",
    "Recovered —> Number of recovered cases —> decimal\n",
    "\"\"\"\n",
    "virus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>700.00000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>350.50000</td>\n",
       "      <td>141.224286</td>\n",
       "      <td>3.077143</td>\n",
       "      <td>3.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>202.21688</td>\n",
       "      <td>859.834237</td>\n",
       "      <td>27.759694</td>\n",
       "      <td>22.586377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>175.75000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>350.50000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>525.25000</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>700.00000</td>\n",
       "      <td>13522.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>396.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sno     Confirmed      Deaths   Recovered\n",
       "count  700.00000    700.000000  700.000000  700.000000\n",
       "mean   350.50000    141.224286    3.077143    3.407143\n",
       "std    202.21688    859.834237   27.759694   22.586377\n",
       "min      1.00000      0.000000    0.000000    0.000000\n",
       "25%    175.75000      2.000000    0.000000    0.000000\n",
       "50%    350.50000      8.000000    0.000000    0.000000\n",
       "75%    525.25000     55.250000    0.000000    1.000000\n",
       "max    700.00000  13522.000000  414.000000  396.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how prevalent missing values are in the data\n",
    "# defining a function to check null values and null values %:\n",
    "def null_cols(ds):\n",
    "    \"\"\"\n",
    "    Checks whether the value in each field is missing (null) and return either \n",
    "    True or False for each field, totaling up the number of True values by column.\n",
    "\n",
    "    Then does the same, but returns the value as a percentage. Useful to decide where \n",
    "    to drop.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ds.isnull().sum(), ds.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_abs, nulls_rel = null_cols(virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno                 0\n",
       "Date                0\n",
       "Province/State    164\n",
       "Country             0\n",
       "Last Update         0\n",
       "Confirmed           0\n",
       "Deaths              0\n",
       "Recovered           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 164 in Provice/State\n",
    "nulls_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno                0.00\n",
       "Date               0.00\n",
       "Province/State    23.43\n",
       "Country            0.00\n",
       "Last Update        0.00\n",
       "Confirmed          0.00\n",
       "Deaths             0.00\n",
       "Recovered          0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Province/State 23,43% null valls\n",
    "nulls_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sno: 700 uniques',\n",
       " 'Date: 13 uniques',\n",
       " 'Province/State: 57 uniques',\n",
       " 'Country: 31 uniques',\n",
       " 'Last Update: 92 uniques',\n",
       " 'Confirmed: 183 uniques',\n",
       " 'Deaths: 15 uniques',\n",
       " 'Recovered: 36 uniques']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Unique entries per colum:\n",
    "[col + \": \" + str(len(virus[col].unique())) + \" uniques\" for col in virus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['China', 'US', 'Japan', 'Thailand', 'South Korea',\n",
       "       'Mainland China', 'Hong Kong', 'Macau', 'Taiwan', 'Singapore',\n",
       "       'Philippines', 'Malaysia', 'Vietnam', 'Australia', 'Mexico',\n",
       "       'Brazil', 'France', 'Nepal', 'Canada', 'Cambodia', 'Sri Lanka',\n",
       "       'Ivory Coast', 'Germany', 'Finland', 'United Arab Emirates',\n",
       "       'India', 'Italy', 'Sweden', 'Russia', 'Spain', 'UK'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Unique \"Countries\"\n",
    "virus[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['China', 'US', 'Japan', 'Thailand', 'South Korea', 'Taiwan',\n",
       "       'Singapore', 'Philippines', 'Malaysia', 'Vietnam', 'Australia',\n",
       "       'Mexico', 'Brazil', 'France', 'Nepal', 'Canada', 'Cambodia',\n",
       "       'Sri Lanka', 'Ivory Coast', 'Germany', 'Finland',\n",
       "       'United Arab Emirates', 'India', 'Italy', 'Sweden', 'Russia',\n",
       "       'Spain', 'UK'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicating the data\n",
    "c_virus = virus.copy()\n",
    "\n",
    "# correcting China entries\n",
    "c_virus[\"Country\"] = c_virus[\"Country\"].str.replace('Mainland China', 'China')\n",
    "c_virus[\"Country\"] = c_virus[\"Country\"].str.replace('Hong Kong', 'China')\n",
    "#c_virus[\"Country\"] = c_virus[\"Country\"].str.replace('Taiwan', 'China') // We decided to \n",
    "# keep Taiwan as a Country\n",
    "c_virus[\"Country\"] = c_virus[\"Country\"].str.replace(' China', 'China')\n",
    "c_virus[\"Country\"] = c_virus[\"Country\"].str.replace('Macau', 'China')\n",
    "c_virus[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting 'Taiwan as a country' (1 entry)\n",
    "c_virus[(c_virus[\"Province/State\"] == \"Taiwan\") & (c_virus[\"Country\"] != \"Taiwan\")]\n",
    "c_virus.loc[(c_virus[\"Province/State\"] == \"Taiwan\") & (c_virus[\"Country\"] != \"Taiwan\"), \"Country\"] = \"Taiwan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Date</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sno, Date, Province/State, Country, Last Update, Confirmed, Deaths, Recovered]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_virus[(c_virus[\"Province/State\"] == \"Taiwan\") & (c_virus[\"Country\"] != \"Taiwan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-01-22 12:00:00', '2020-01-23 12:00:00',\n",
       "       '2020-01-24 12:00:00', '2020-01-24 16:00:00',\n",
       "       '2020-01-25 22:00:00', '2020-01-25 12:00:00',\n",
       "       '2020-01-26 23:00:00', '2020-01-27 20:30:00',\n",
       "       '2020-01-28 23:00:00', '2020-01-28 18:00:00',\n",
       "       '2020-01-29 21:00:00', '2020-01-30 21:30:00',\n",
       "       '2020-01-31 19:00:00', '2020-01-02 23:33:00',\n",
       "       '2020-02-02 02:13:00', '2020-02-02 01:23:00',\n",
       "       '2020-02-02 00:53:00', '2020-02-02 01:53:00',\n",
       "       '2020-02-02 01:33:00', '2020-01-02 23:43:00',\n",
       "       '2020-02-02 01:13:00', '2020-02-02 01:03:00',\n",
       "       '2020-02-02 03:05:00', '2020-02-02 00:23:00',\n",
       "       '2020-02-02 03:43:00', '2020-02-02 03:23:00',\n",
       "       '2020-02-02 02:53:00', '2020-01-02 15:53:00',\n",
       "       '2020-01-02 15:23:00', '2020-02-02 02:03:00',\n",
       "       '2020-01-02 15:43:00', '2020-02-02 01:43:00',\n",
       "       '2020-02-02 02:33:00', '2020-02-02 00:43:00',\n",
       "       '2020-01-02 18:53:00', '2020-01-31 10:37:00',\n",
       "       '2020-02-02 02:23:00', '2020-01-31 15:20:00',\n",
       "       '2020-01-02 05:37:00', '2020-01-31 08:15:00',\n",
       "       '2020-01-02 01:52:00', '2020-01-02 07:38:00',\n",
       "       '2020-01-02 18:12:00', '2020-02-02 03:33:00',\n",
       "       '2020-01-31 16:13:00', '2020-01-02 19:43:00',\n",
       "       '2020-01-02 02:13:00', '2020-01-02 19:53:00',\n",
       "       '2020-02-02 23:43:00', '2020-03-02 01:33:00',\n",
       "       '2020-03-02 01:03:00', '2020-03-02 00:53:00',\n",
       "       '2020-02-02 23:33:00', '2020-03-02 01:13:00',\n",
       "       '2020-03-02 00:03:00', '2020-02-02 08:43:00',\n",
       "       '2020-03-02 00:13:00', '2020-03-02 00:23:00',\n",
       "       '2020-02-02 18:03:00', '2020-03-02 00:43:00',\n",
       "       '2020-02-02 23:23:00', '2020-02-02 09:43:00',\n",
       "       '2020-02-02 23:53:00', '2020-02-02 05:33:00',\n",
       "       '2020-02-02 04:23:00', '2020-02-02 05:43:00',\n",
       "       '2020-02-02 22:33:00', '2020-02-02 06:03:00',\n",
       "       '2020-04-02 01:23:00', '2020-04-02 01:43:00',\n",
       "       '2020-04-02 00:43:00', '2020-03-02 23:43:00',\n",
       "       '2020-04-02 01:03:00', '2020-04-02 00:53:00',\n",
       "       '2020-03-02 09:23:00', '2020-04-02 00:13:00',\n",
       "       '2020-03-02 11:33:00', '2020-04-02 02:33:00',\n",
       "       '2020-04-02 00:33:00', '2020-04-02 00:23:00',\n",
       "       '2020-03-02 23:23:00', '2020-03-02 17:11:00',\n",
       "       '2020-03-02 23:13:00', '2020-03-02 13:53:00',\n",
       "       '2020-03-02 23:03:00', '2020-03-02 03:03:00',\n",
       "       '2020-04-02 02:13:00', '2020-04-02 01:33:00',\n",
       "       '2020-03-02 20:53:00', '2020-03-02 21:43:00',\n",
       "       '2020-03-02 03:53:00', '2020-04-02 00:03:00'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the unique Last Updates\n",
    "c_virus[\"Last Update\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Time (hh:mm:ss) from the 'Last Update' col\n",
    "def time_eater(entity):\n",
    "    \"\"\"\n",
    "    Checks if an entity has a time after a date, and removes the time.\n",
    "    \"\"\"\n",
    "    return re.sub(\"\\s+\\d{1,2}\\:\\d{2}:\\d{2}\", \"\", entity)\n",
    "   \n",
    "# applies the time_eater function to the 'Last Update' col to clean the time\n",
    "c_virus[\"Last Update\"] = c_virus[\"Last Update\"].apply(time_eater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25',\n",
       "       '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29',\n",
       "       '2020-01-30', '2020-01-31', '2020-01-02', '2020-02-02',\n",
       "       '2020-03-02', '2020-04-02'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_virus[\"Last Update\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean 'Date' as done for 'Last Update' (FIRST confirm that the time_eater func \n",
    "## applies correctly to 'Date' col format)\n",
    "# TODO: Check the 'Last Update' against 'Date'\n",
    "# TODO: Correct 'Last Update' month & or day\n",
    "# TODO: Drop rows where 'Last Update' is after 02/02/202\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01/22/2020 12:00:00', '01/23/2020 12:00:00',\n",
       "       '01/24/2020 12:00:00', '01/25/2020 22:00:00',\n",
       "       '01/26/2020 23:00:00', '01/27/2020 20:30:00',\n",
       "       '01/28/2020 23:00:00', '01/29/2020 21:00:00',\n",
       "       '01/30/2020 21:30:00', '01/31/2020 19:00:00',\n",
       "       '02/01/2020 23:00:00', '02/02/2020 21:00:00',\n",
       "       '02/03/2020 21:40:00'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_virus[\"Date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a condition that will filter the data and show us only columns where the number \n",
    "# of null values were greater than zero for each dataset:\n",
    "\n",
    "nulls_abs[nulls_abs > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-7e555fc1ea73>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-7e555fc1ea73>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    \"\"\"Adding col names to a list to be droped; in this case as long as the col has a\u001b[0m\n\u001b[0m                                                                                      \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "DON'T RUN THIS CELL YET!!!\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Judgement call: droping information that we don't think it's going to be very useful \n",
    "# to our analysis (removing those columns from your datasets) with the drop method.\n",
    "# We will add these column names to a list, and then we will pass those columns to the \n",
    "# drop method and indicate that we want columns (not rows) dropped by setting the axis \n",
    "# parameter to 1.\n",
    "\n",
    "# defining a function to create a list:\n",
    "def drop_cols(bad_cols):\n",
    "    \"\"\"Adding col names to a list to be droped; in this case as long as the col has a \n",
    "    single null value in it, since, in this case, if it has one, their all null.\"\"\"\n",
    "    return list(bad_cols[bad_cols > 0].index)\n",
    "\n",
    "# Droping the columns with null values is (always?) a judgment call. \n",
    "# In a discussion on analyticsvidhya.com \n",
    "# (what-should-be-the-allowed-percentage-of-missing-values/2456), the sugestion is to drop\n",
    "# after the 30% ceiling has been reached. Still, it will depend.\n",
    "\n",
    "# For starters I'll check what entities have the missing values and what don't;\n",
    "missing = merged.loc[(merged[\"ViewCount\"].notna() != True)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = virus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.drop(\"Date\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds[\"Last Update\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
